{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalexam03.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "train_dataset_path = '/content/cat_and_dog/training_set/training_set'\n",
        "test_dataset_path =  '/content/cat_and_dog/test_set/test_set'\n",
        "\n",
        "trans = transforms.Compose([transforms.Resize((96, 96)), transforms.ToTensor()])\n",
        "train_data = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = trans)\n",
        "test_data = torchvision.datasets.ImageFolder(root = test_dataset_path, transform = trans)\n",
        "\n",
        "print('class:', train_data.classes)\n",
        "print('train_data:', len(train_data))\n",
        "print('test_data:', len(test_data))\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, \n",
        "                                                batch_size = 32,\n",
        "                                                shuffle = True)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, \n",
        "                                               batch_size = 32,\n",
        "                                               shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaOWaXHYdxxu",
        "outputId": "24c252f6-7128-40d0-cc75-f9add4cdc725"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class: ['cats', 'dogs']\n",
            "train_data: 8005\n",
            "test_data: 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module): \n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6,\n",
        "                           kernel_size = 3, stride = 1, padding = 2)\n",
        "    self.bn1 = nn.BatchNorm2d(6)\n",
        "    self.max_pool1 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12,\n",
        "                           kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.bn2 = nn.BatchNorm2d(12)\n",
        "    self.max_pool2 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 12, out_channels = 24,\n",
        "                           kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.bn3 = nn.BatchNorm2d(24)\n",
        "    self.max_pool3 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.conv4 = nn.Conv2d(in_channels = 24, out_channels = 48, \n",
        "                           kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.bn4 = nn.BatchNorm2d(48)\n",
        "    self.max_pool4 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.dropout1 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(1728, 512)\n",
        "    #self.bn5 = nn.BatchNorm1d(512)\n",
        "    #self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    #self.dropout3 = nn.Dropout(0.5)\n",
        "    self.fc3 = nn.Linear(256, 5)\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.bn4(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool4(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    #x = self.bn5(x)\n",
        "    #x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    #x = self.dropout3(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DrWVIrVyrRpV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "epoch_count = 15\n",
        "\n",
        "# gpu check\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# model set (gpu)\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "# SGD optimizer\n",
        "#optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
        "optimizer = optim.Adam(model.parameters()) \n",
        "\n",
        "# MSE loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "\n",
        "  # set train mode\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (x, y) in enumerate(train_data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print('Train Epoch: {} [{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, len(train_data_loader.dataset),\n",
        "        100. * batch_idx / len(train_data_loader), loss.item()))\n",
        "\n",
        "  # set test mode\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for x, y in test_data_loader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_pred = model(x)\n",
        "    test_loss += loss_fn(y_pred, y).item()  # sum up batch loss\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_data_loader.dataset)\n",
        "\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_data_loader.dataset),\n",
        "      100. * correct / len(test_data_loader.dataset)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GeklQvjrRvz",
        "outputId": "8e0ca352-decb-4110-f5ea-df81fd39678e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (max_pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=1728, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=5, bias=True)\n",
            ")\n",
            "Train Epoch: 0 [8005 (100%)]\tLoss: 0.787009\n",
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 1386/2023 (69%)\n",
            "\n",
            "Train Epoch: 1 [8005 (100%)]\tLoss: 0.501768\n",
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 1400/2023 (69%)\n",
            "\n",
            "Train Epoch: 2 [8005 (100%)]\tLoss: 0.744642\n",
            "\n",
            "Test set: Average loss: 0.0174, Accuracy: 1466/2023 (72%)\n",
            "\n",
            "Train Epoch: 3 [8005 (100%)]\tLoss: 0.320209\n",
            "\n",
            "Test set: Average loss: 0.0179, Accuracy: 1426/2023 (70%)\n",
            "\n",
            "Train Epoch: 4 [8005 (100%)]\tLoss: 0.751989\n",
            "\n",
            "Test set: Average loss: 0.0142, Accuracy: 1604/2023 (79%)\n",
            "\n",
            "Train Epoch: 5 [8005 (100%)]\tLoss: 0.635623\n",
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 1411/2023 (70%)\n",
            "\n",
            "Train Epoch: 6 [8005 (100%)]\tLoss: 0.515182\n",
            "\n",
            "Test set: Average loss: 0.0141, Accuracy: 1630/2023 (81%)\n",
            "\n",
            "Train Epoch: 7 [8005 (100%)]\tLoss: 1.501837\n",
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 1583/2023 (78%)\n",
            "\n",
            "Train Epoch: 8 [8005 (100%)]\tLoss: 1.214396\n",
            "\n",
            "Test set: Average loss: 0.0131, Accuracy: 1640/2023 (81%)\n",
            "\n",
            "Train Epoch: 9 [8005 (100%)]\tLoss: 0.786178\n",
            "\n",
            "Test set: Average loss: 0.0134, Accuracy: 1618/2023 (80%)\n",
            "\n",
            "Train Epoch: 10 [8005 (100%)]\tLoss: 0.696419\n",
            "\n",
            "Test set: Average loss: 0.0135, Accuracy: 1631/2023 (81%)\n",
            "\n",
            "Train Epoch: 11 [8005 (100%)]\tLoss: 0.048362\n",
            "\n",
            "Test set: Average loss: 0.0120, Accuracy: 1696/2023 (84%)\n",
            "\n",
            "Train Epoch: 12 [8005 (100%)]\tLoss: 1.150491\n",
            "\n",
            "Test set: Average loss: 0.0126, Accuracy: 1670/2023 (83%)\n",
            "\n",
            "Train Epoch: 13 [8005 (100%)]\tLoss: 1.209101\n",
            "\n",
            "Test set: Average loss: 0.0148, Accuracy: 1580/2023 (78%)\n",
            "\n",
            "Train Epoch: 14 [8005 (100%)]\tLoss: 0.307748\n",
            "\n",
            "Test set: Average loss: 0.0118, Accuracy: 1702/2023 (84%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}