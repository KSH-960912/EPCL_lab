{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalexam02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkhKVxktMsiG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def load_titanic_dataset():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/titanic_test.csv') as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    next(csvreader, None)\n",
        "    rows = []\n",
        "    for row in csvreader:\n",
        "      rows.append(row)\n",
        "\n",
        "  global data, input_cnt, output_cnt\n",
        "  input_cnt, output_cnt = 30, 1\n",
        "  data = np.zeros([len(rows), input_cnt+output_cnt])\n",
        "\n",
        "  for n, row in enumerate(rows):\n",
        "    if row[0] == 'male': data[n, 0] = 1\n",
        "    if row[0] == 'female': data[n, 1] = 1\n",
        "    data[n, 29:] = row[1:]\n",
        "\n",
        "def arrange_data(mb_size):\n",
        "  global data, shuffle_map, test_begin_idx\n",
        "  shuffle_map = np.arange(data.shape[0])\n",
        "  np.random.shuffle(shuffle_map)\n",
        "  step_count = int(data.shape[0] * 0.8) // mb_size\n",
        "  test_begin_idx = step_count * mb_size\n",
        "  return step_count\n",
        "\n",
        "def get_test_data():\n",
        "  global data, shuffle_map, test_begin_idx, output_cnt\n",
        "  test_data = data[shuffle_map[test_begin_idx:]]\n",
        "  return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n",
        "\n",
        "def get_train_data(mb_size, nth):\n",
        "  global data, shuffle_map, test_begin_idx, output_cnt\n",
        "  if nth == 0:\n",
        "    np.random.shuffle(shuffle_map[:test_begin_idx])\n",
        "  train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n",
        "  return train_data[:, :-output_cnt], train_data[:, -output_cnt:]\n",
        "\n",
        "def eval_accuracy(output, y):\n",
        "  mdiff = np.mean(np.abs((output - y)/y))\n",
        "  return 1 - mdiff"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(30, 25)\n",
        "    self.fc2 = nn.Linear(25, 20)\n",
        "    self.fc3 = nn.Linear(20, 15)\n",
        "    self.fc4 = nn.Linear(15, 5)\n",
        "    self.fc5 = nn.Linear(5, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc4(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc5(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ksy46Y2LM7P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "LEARNING_RATE = 0.01 \n",
        "epoch_count = 100\n",
        "mb_size = 5\n",
        "\n",
        "# dataset load\n",
        "load_titanic_dataset()\n",
        "step_count = arrange_data(mb_size)\n",
        "test_x, test_y = get_test_data()"
      ],
      "metadata": {
        "id": "ZZc7qMZFM7Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu check\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# model set (gpu)\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "# SGD optimizer\n",
        "#optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "  losses, accs = [], []\n",
        "\n",
        "  # set train mode\n",
        "  model.train()\n",
        "\n",
        "  for n in range(step_count):\n",
        "    # optimizer init\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get train data\n",
        "    train_x, train_y = get_train_data(mb_size, n)\n",
        "\n",
        "    # dataset to torch\n",
        "    x = torch.from_numpy(train_x).float()\n",
        "    y = torch.from_numpy(train_y).float()\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(x)\n",
        "    acc = eval_accuracy(y_pred.to('cpu').detach().numpy(), train_y)\n",
        "    accs.append(acc)\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # weight, bias 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "  # run test & eval\n",
        "  model.eval()\n",
        "  x = torch.from_numpy(test_x).float()\n",
        "  x = x.to(device)\n",
        "  y_pred = model(x)\n",
        "  acc = eval_accuracy(y_pred.to('cpu').detach().numpy(), test_y)\n",
        "\n",
        "  print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'. \\\n",
        "        format(epoch+1, np.mean(losses), np.mean(accs), acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJFNuTpvM7UD",
        "outputId": "14febe24-847e-4c56-ce2c-a10a846afd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "Net(\n",
            "  (fc1): Linear(in_features=30, out_features=25, bias=True)\n",
            "  (fc2): Linear(in_features=25, out_features=20, bias=True)\n",
            "  (fc3): Linear(in_features=20, out_features=15, bias=True)\n",
            "  (fc4): Linear(in_features=15, out_features=5, bias=True)\n",
            "  (fc5): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n",
            "Epoch 1: loss=4.060, accuracy=0.204/0.509\n",
            "Epoch 2: loss=0.719, accuracy=0.533/0.536\n",
            "Epoch 3: loss=0.665, accuracy=0.550/0.527\n",
            "Epoch 4: loss=0.646, accuracy=0.557/0.551\n",
            "Epoch 5: loss=0.630, accuracy=0.568/0.564\n",
            "Epoch 6: loss=0.635, accuracy=0.569/0.566\n",
            "Epoch 7: loss=0.628, accuracy=0.573/0.573\n",
            "Epoch 8: loss=0.619, accuracy=0.575/0.573\n",
            "Epoch 9: loss=0.626, accuracy=0.576/0.568\n",
            "Epoch 10: loss=0.622, accuracy=0.578/0.563\n",
            "Epoch 11: loss=0.622, accuracy=0.579/0.555\n",
            "Epoch 12: loss=0.623, accuracy=0.576/0.571\n",
            "Epoch 13: loss=0.617, accuracy=0.579/0.569\n",
            "Epoch 14: loss=0.624, accuracy=0.576/0.568\n",
            "Epoch 15: loss=0.620, accuracy=0.581/0.569\n",
            "Epoch 16: loss=0.624, accuracy=0.578/0.576\n",
            "Epoch 17: loss=0.626, accuracy=0.579/0.578\n",
            "Epoch 18: loss=0.614, accuracy=0.580/0.549\n",
            "Epoch 19: loss=0.618, accuracy=0.578/0.572\n",
            "Epoch 20: loss=0.621, accuracy=0.580/0.552\n",
            "Epoch 21: loss=0.622, accuracy=0.579/0.547\n",
            "Epoch 22: loss=0.615, accuracy=0.581/0.592\n",
            "Epoch 23: loss=0.620, accuracy=0.581/0.546\n",
            "Epoch 24: loss=0.612, accuracy=0.583/0.569\n",
            "Epoch 25: loss=0.616, accuracy=0.581/0.589\n",
            "Epoch 26: loss=0.616, accuracy=0.582/0.575\n",
            "Epoch 27: loss=0.617, accuracy=0.583/0.566\n",
            "Epoch 28: loss=0.617, accuracy=0.580/0.592\n",
            "Epoch 29: loss=0.616, accuracy=0.582/0.572\n",
            "Epoch 30: loss=0.617, accuracy=0.581/0.577\n",
            "Epoch 31: loss=0.618, accuracy=0.581/0.584\n",
            "Epoch 32: loss=0.615, accuracy=0.580/0.564\n",
            "Epoch 33: loss=0.625, accuracy=0.579/0.581\n",
            "Epoch 34: loss=0.611, accuracy=0.581/0.594\n",
            "Epoch 35: loss=0.626, accuracy=0.582/0.563\n",
            "Epoch 36: loss=0.621, accuracy=0.580/0.558\n",
            "Epoch 37: loss=0.613, accuracy=0.584/0.509\n",
            "Epoch 38: loss=0.619, accuracy=0.578/0.552\n",
            "Epoch 39: loss=0.620, accuracy=0.579/0.571\n",
            "Epoch 40: loss=0.618, accuracy=0.580/0.586\n",
            "Epoch 41: loss=0.624, accuracy=0.579/0.567\n",
            "Epoch 42: loss=0.618, accuracy=0.580/0.550\n",
            "Epoch 43: loss=0.621, accuracy=0.579/0.572\n",
            "Epoch 44: loss=0.625, accuracy=0.578/0.577\n",
            "Epoch 45: loss=0.621, accuracy=0.579/0.582\n",
            "Epoch 46: loss=0.617, accuracy=0.581/0.568\n",
            "Epoch 47: loss=0.611, accuracy=0.582/0.585\n",
            "Epoch 48: loss=0.616, accuracy=0.580/0.579\n",
            "Epoch 49: loss=0.621, accuracy=0.584/0.567\n",
            "Epoch 50: loss=0.621, accuracy=0.577/0.569\n",
            "Epoch 51: loss=0.616, accuracy=0.580/0.574\n",
            "Epoch 52: loss=0.619, accuracy=0.579/0.570\n",
            "Epoch 53: loss=0.615, accuracy=0.582/0.562\n",
            "Epoch 54: loss=0.618, accuracy=0.579/0.577\n",
            "Epoch 55: loss=0.620, accuracy=0.578/0.559\n",
            "Epoch 56: loss=0.619, accuracy=0.580/0.582\n",
            "Epoch 57: loss=0.613, accuracy=0.581/0.587\n",
            "Epoch 58: loss=0.624, accuracy=0.579/0.585\n",
            "Epoch 59: loss=0.616, accuracy=0.581/0.576\n",
            "Epoch 60: loss=0.625, accuracy=0.578/0.578\n",
            "Epoch 61: loss=0.619, accuracy=0.581/0.579\n",
            "Epoch 62: loss=0.618, accuracy=0.581/0.551\n",
            "Epoch 63: loss=0.623, accuracy=0.577/0.562\n",
            "Epoch 64: loss=0.616, accuracy=0.579/0.566\n",
            "Epoch 65: loss=0.619, accuracy=0.580/0.565\n",
            "Epoch 66: loss=0.620, accuracy=0.579/0.571\n",
            "Epoch 67: loss=0.617, accuracy=0.580/0.555\n",
            "Epoch 68: loss=0.617, accuracy=0.580/0.575\n",
            "Epoch 69: loss=0.630, accuracy=0.578/0.581\n",
            "Epoch 70: loss=0.618, accuracy=0.579/0.579\n",
            "Epoch 71: loss=0.619, accuracy=0.582/0.554\n",
            "Epoch 72: loss=0.617, accuracy=0.580/0.563\n",
            "Epoch 73: loss=0.615, accuracy=0.579/0.576\n",
            "Epoch 74: loss=0.617, accuracy=0.581/0.577\n",
            "Epoch 75: loss=0.615, accuracy=0.581/0.575\n",
            "Epoch 76: loss=0.617, accuracy=0.580/0.563\n",
            "Epoch 77: loss=0.623, accuracy=0.581/0.580\n",
            "Epoch 78: loss=0.617, accuracy=0.579/0.580\n",
            "Epoch 79: loss=0.614, accuracy=0.584/0.573\n",
            "Epoch 80: loss=0.614, accuracy=0.581/0.571\n",
            "Epoch 81: loss=0.615, accuracy=0.583/0.578\n",
            "Epoch 82: loss=0.618, accuracy=0.580/0.579\n",
            "Epoch 83: loss=0.623, accuracy=0.576/0.575\n",
            "Epoch 84: loss=0.629, accuracy=0.580/0.574\n",
            "Epoch 85: loss=0.622, accuracy=0.579/0.554\n",
            "Epoch 86: loss=0.614, accuracy=0.580/0.577\n",
            "Epoch 87: loss=0.615, accuracy=0.581/0.567\n",
            "Epoch 88: loss=0.626, accuracy=0.577/0.582\n",
            "Epoch 89: loss=0.616, accuracy=0.579/0.570\n",
            "Epoch 90: loss=0.616, accuracy=0.583/0.571\n",
            "Epoch 91: loss=0.615, accuracy=0.581/0.595\n",
            "Epoch 92: loss=0.623, accuracy=0.582/0.588\n",
            "Epoch 93: loss=0.621, accuracy=0.580/0.569\n",
            "Epoch 94: loss=0.620, accuracy=0.579/0.567\n",
            "Epoch 95: loss=0.624, accuracy=0.578/0.552\n",
            "Epoch 96: loss=0.621, accuracy=0.579/0.572\n",
            "Epoch 97: loss=0.618, accuracy=0.581/0.562\n",
            "Epoch 98: loss=0.617, accuracy=0.581/0.571\n",
            "Epoch 99: loss=0.617, accuracy=0.580/0.557\n",
            "Epoch 100: loss=0.615, accuracy=0.579/0.577\n"
          ]
        }
      ]
    }
  ]
}