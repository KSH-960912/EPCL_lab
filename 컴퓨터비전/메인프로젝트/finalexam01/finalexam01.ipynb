{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalexam01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vuUGuxrYAjOQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def load_pulsar_dataset():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/pulsar_stars.csv') as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    next(csvreader, None)\n",
        "    rows = []\n",
        "    for row in csvreader:\n",
        "      rows.append(row)\n",
        "\n",
        "  global data, input_cnt, output_cnt\n",
        "  input_cnt, output_cnt = 8, 1\n",
        "  data = np.zeros([len(rows), input_cnt+output_cnt])\n",
        "\n",
        "  for n, row in enumerate(rows):\n",
        "    #if row[0] == 'I': data[n, 0] = 1\n",
        "    #if row[0] == 'M': data[n, 1] = 1\n",
        "    #if row[0] == 'F': data[n, 2] = 1\n",
        "    data[n, 1:] = row[1:]\n",
        "\n",
        "def arrange_data(mb_size):\n",
        "  global data, shuffle_map, test_begin_idx\n",
        "  shuffle_map = np.arange(data.shape[0])\n",
        "  np.random.shuffle(shuffle_map)\n",
        "  step_count = int(data.shape[0] * 0.8) // mb_size\n",
        "  test_begin_idx = step_count * mb_size\n",
        "  return step_count\n",
        "\n",
        "def get_test_data():\n",
        "  global data, shuffle_map, test_begin_idx, output_cnt\n",
        "  test_data = data[shuffle_map[test_begin_idx:]]\n",
        "  return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n",
        "\n",
        "def get_train_data(mb_size, nth):\n",
        "  global data, shuffle_map, test_begin_idx, output_cnt\n",
        "  if nth == 0:\n",
        "    np.random.shuffle(shuffle_map[:test_begin_idx])\n",
        "  train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n",
        "  return train_data[:, :-output_cnt], train_data[:, -output_cnt:]\n",
        "\n",
        "def eval_accuracy(output, y):\n",
        "  estimate = np.greater(output, 0.5)\n",
        "  answer = np.greater(y, 0.5)\n",
        "  correct = np.equal(estimate, answer)\n",
        "  return np.mean(correct)\n",
        "  #mdiff = np.mean(np.abs((output - y)/y))\n",
        "  #return 1 - mdiff  #회귀분석에서의 정확도"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Pytorch 형태의 네트워크 구조\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(8, 1) #입력이 8 출력이 1인 퍼셉트론\n",
        "    self.sigm = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.sigm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "25ffWkeTB-uv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "epoch_count = 50\n",
        "mb_size = 10\n",
        "\n",
        "# dataset load\n",
        "load_pulsar_dataset()\n",
        "step_count = arrange_data(mb_size)\n",
        "test_x, test_y = get_test_data()"
      ],
      "metadata": {
        "id": "GUjxqPQtB-xM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu check\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# model set (gpu)\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "# SGD optimizer\n",
        "#optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "  losses, accs = [], []\n",
        "\n",
        "  # set train mode\n",
        "  model.train()\n",
        "\n",
        "  for n in range(step_count):\n",
        "    # optimizer init\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get train data\n",
        "    train_x, train_y = get_train_data(mb_size, n)\n",
        "\n",
        "    # dataset to torch\n",
        "    x = torch.from_numpy(train_x).float()\n",
        "    y = torch.from_numpy(train_y).float()\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(x)\n",
        "    acc = eval_accuracy(y_pred.to('cpu').detach().numpy(), train_y)\n",
        "    accs.append(acc)\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # weight, bias 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "  # run test & eval\n",
        "  model.eval()\n",
        "  x = torch.from_numpy(test_x).float()\n",
        "  x = x.to(device)\n",
        "  y_pred = model(x)\n",
        "  acc = eval_accuracy(y_pred.to('cpu').detach().numpy(), test_y)\n",
        "\n",
        "  print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'. \\\n",
        "        format(epoch+1, np.mean(losses), np.mean(accs), acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcbQi_DcB-3n",
        "outputId": "1661a6dd-0c79-4dfb-a8db-d432f298f6a6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "Net(\n",
            "  (fc1): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            ")\n",
            "Epoch 1: loss=1.527, accuracy=0.901/0.971\n",
            "Epoch 2: loss=0.103, accuracy=0.971/0.972\n",
            "Epoch 3: loss=0.099, accuracy=0.972/0.974\n",
            "Epoch 4: loss=0.097, accuracy=0.973/0.978\n",
            "Epoch 5: loss=0.096, accuracy=0.974/0.977\n",
            "Epoch 6: loss=0.095, accuracy=0.974/0.978\n",
            "Epoch 7: loss=0.093, accuracy=0.974/0.977\n",
            "Epoch 8: loss=0.092, accuracy=0.974/0.978\n",
            "Epoch 9: loss=0.091, accuracy=0.976/0.979\n",
            "Epoch 10: loss=0.090, accuracy=0.975/0.979\n",
            "Epoch 11: loss=0.089, accuracy=0.976/0.978\n",
            "Epoch 12: loss=0.088, accuracy=0.976/0.980\n",
            "Epoch 13: loss=0.089, accuracy=0.975/0.980\n",
            "Epoch 14: loss=0.087, accuracy=0.976/0.977\n",
            "Epoch 15: loss=0.088, accuracy=0.975/0.978\n",
            "Epoch 16: loss=0.087, accuracy=0.976/0.977\n",
            "Epoch 17: loss=0.086, accuracy=0.975/0.980\n",
            "Epoch 18: loss=0.087, accuracy=0.975/0.982\n",
            "Epoch 19: loss=0.086, accuracy=0.976/0.979\n",
            "Epoch 20: loss=0.085, accuracy=0.976/0.979\n",
            "Epoch 21: loss=0.085, accuracy=0.976/0.980\n",
            "Epoch 22: loss=0.085, accuracy=0.976/0.981\n",
            "Epoch 23: loss=0.084, accuracy=0.977/0.980\n",
            "Epoch 24: loss=0.084, accuracy=0.977/0.980\n",
            "Epoch 25: loss=0.084, accuracy=0.977/0.979\n",
            "Epoch 26: loss=0.084, accuracy=0.976/0.981\n",
            "Epoch 27: loss=0.084, accuracy=0.977/0.980\n",
            "Epoch 28: loss=0.083, accuracy=0.977/0.980\n",
            "Epoch 29: loss=0.084, accuracy=0.977/0.977\n",
            "Epoch 30: loss=0.084, accuracy=0.976/0.981\n",
            "Epoch 31: loss=0.083, accuracy=0.977/0.981\n",
            "Epoch 32: loss=0.083, accuracy=0.977/0.981\n",
            "Epoch 33: loss=0.083, accuracy=0.977/0.980\n",
            "Epoch 34: loss=0.083, accuracy=0.977/0.980\n",
            "Epoch 35: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 36: loss=0.083, accuracy=0.977/0.979\n",
            "Epoch 37: loss=0.084, accuracy=0.977/0.980\n",
            "Epoch 38: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 39: loss=0.082, accuracy=0.977/0.979\n",
            "Epoch 40: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 41: loss=0.082, accuracy=0.977/0.981\n",
            "Epoch 42: loss=0.081, accuracy=0.977/0.980\n",
            "Epoch 43: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 44: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 45: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 46: loss=0.082, accuracy=0.977/0.980\n",
            "Epoch 47: loss=0.082, accuracy=0.977/0.982\n",
            "Epoch 48: loss=0.081, accuracy=0.978/0.980\n",
            "Epoch 49: loss=0.082, accuracy=0.977/0.979\n",
            "Epoch 50: loss=0.081, accuracy=0.978/0.980\n"
          ]
        }
      ]
    }
  ]
}